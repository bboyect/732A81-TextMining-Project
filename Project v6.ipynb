{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb6d45c-8659-4a52-88db-d5d6f863b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from transformers import RobertaTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e62a985-5506-4602-ae11-ad9ac3d901e3",
   "metadata": {},
   "source": [
    "# Load Data+ Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ababa1a-ef94-4fc1-bd9a-3a69e8301fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 16s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "columns_to_load = ['app_name', 'language', 'review','recommended']\n",
    "df = pd.read_csv('steam_reviews.csv', usecols=columns_to_load) \n",
    "eng_df_og = df[df['language'] == 'english']\n",
    "eng_df_og = eng_df_og.dropna(subset=['review'])\n",
    "eng_df_og.head(10)\n",
    "eng_df = eng_df_og.sample(frac=0.01, random_state=42)\n",
    "eng_df['recommended'] = eng_df['recommended'].map({True: 1, False: 0})\n",
    "eng_df.reset_index(drop=True, inplace=True)\n",
    "def preprocess_review(review):\n",
    "    return review.lower()  \n",
    "\n",
    "eng_df['processed_review'] = eng_df['review'].apply(preprocess_review)\n",
    "eng_df = eng_df.drop(columns=['review'])\n",
    "train_df, valid_df = train_test_split(eng_df, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9352dbf3-207c-427b-a9c5-86ecc9e4e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_evaluate_sentiment(texts, pipeline , batch_size=1024):\n",
    "    labels = []\n",
    "    scores = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_results = pipeline(batch_texts)\n",
    "        labels.extend([res['label'] for res in batch_results])\n",
    "        scores.extend([res['score'] for res in batch_results])\n",
    "    return labels, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdfe55b-d590-4dfa-bb3d-e391c5cc4c05",
   "metadata": {},
   "source": [
    "## Base RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0958620f-ca1a-48d3-879a-b0dc167c26a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1031\n",
      "           1       0.89      1.00      0.94      8588\n",
      "\n",
      "    accuracy                           0.89      9619\n",
      "   macro avg       0.45      0.50      0.47      9619\n",
      "weighted avg       0.80      0.89      0.84      9619\n",
      "\n",
      "CPU times: total: 1min 48s\n",
      "Wall time: 1min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericchenta\\anaconda3\\envs\\textproj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ericchenta\\anaconda3\\envs\\textproj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ericchenta\\anaconda3\\envs\\textproj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_base_roberta = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU (device 0) if available, else use CPU (-1)\n",
    "base_roberta_sentiment_pipeline = TextClassificationPipeline(model=model_base_roberta, tokenizer=tokenizer, framework='pt', device=device, truncation=True)\n",
    "base_roberta_df = valid_df.copy()\n",
    "\n",
    "result_base = my_evaluate_sentiment(base_roberta_df['processed_review'].tolist(),pipeline=base_roberta_sentiment_pipeline)\n",
    "base_roberta_df['base_roberta_sentiment'] = result_base[0]\n",
    "base_roberta_df['base_roberta_sentiment'] = base_roberta_df['base_roberta_sentiment'].map({'LABEL_1': 1, 'LABEL_0': 0})\n",
    "print(classification_report(base_roberta_df['recommended'],base_roberta_df['base_roberta_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16995dd-c1c6-4682-844a-f42db82fba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_base = base_roberta_df[base_roberta_df['recommended'] != base_roberta_df['base_roberta_sentiment']]\n",
    "filtered_df_base.to_excel('base_roberta_mismatched_data.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512647d6-6a11-46ea-ba3a-802421ca58d5",
   "metadata": {},
   "source": [
    "## Own Fine Tune EPO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf409bf-5f66-4b86-ac9e-c71374792bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1031\n",
      "           1       0.97      0.98      0.97      8588\n",
      "\n",
      "    accuracy                           0.95      9619\n",
      "   macro avg       0.89      0.86      0.87      9619\n",
      "weighted avg       0.95      0.95      0.95      9619\n",
      "\n",
      "CPU times: total: 1min 47s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "###USING MY FINE TUNED\n",
    "\n",
    "model_path_epo3 = './Fine_tuned_epo3'  # Update model path\n",
    "model_epo3 = RobertaForSequenceClassification.from_pretrained(model_path_epo3)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "device = 0 if torch.cuda.is_available() else -1  \n",
    "my_finetune_sentiment_pipeline_epo3 = TextClassificationPipeline(model=model_epo3, tokenizer=tokenizer, framework='pt', device=device, truncation=True)\n",
    "\n",
    "my_finetunedf_epo3 = valid_df.copy()\n",
    "results = my_evaluate_sentiment(my_finetunedf_epo3['processed_review'].tolist(),pipeline=my_finetune_sentiment_pipeline_epo3)\n",
    "my_finetunedf_epo3['my_finetune_roberta_sentiment'], my_finetunedf_epo3['my_finetune_roberta_score'] = results[0], results[1]\n",
    "my_finetunedf_epo3['my_finetune_roberta_sentiment'] = my_finetunedf_epo3['my_finetune_roberta_sentiment'].map({'LABEL_1': 1, 'LABEL_0': 0})\n",
    "print(classification_report(my_finetunedf_epo3['recommended'],my_finetunedf_epo3['my_finetune_roberta_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5cc74f-ebf2-4327-a106-497d123ffc03",
   "metadata": {},
   "source": [
    "## Own Fine Tune EPO4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be24f83e-8e20-4c39-be44-19c641af688d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1031\n",
      "           1       0.97      0.97      0.97      8588\n",
      "\n",
      "    accuracy                           0.95      9619\n",
      "   macro avg       0.87      0.87      0.87      9619\n",
      "weighted avg       0.95      0.95      0.95      9619\n",
      "\n",
      "CPU times: total: 1min 49s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_path_epo4 = './Fine_tuned_epo4'  # Update model path\n",
    "model_epo4 = RobertaForSequenceClassification.from_pretrained(model_path_epo4)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU (device 0) if available, else use CPU (-1)\n",
    "my_finetune_sentiment_pipeline_epo4 = TextClassificationPipeline(model=model_epo4, tokenizer=tokenizer, framework='pt', device=device, truncation=True)\n",
    "\n",
    "my_finetunedf_epo4 = valid_df.copy()\n",
    "results = my_evaluate_sentiment(my_finetunedf_epo4['processed_review'].tolist(),pipeline=my_finetune_sentiment_pipeline_epo4)\n",
    "my_finetunedf_epo4['my_finetune_roberta_sentiment'], my_finetunedf_epo4['my_finetune_roberta_score'] = results[0], results[1]\n",
    "my_finetunedf_epo4['my_finetune_roberta_sentiment'] = my_finetunedf_epo4['my_finetune_roberta_sentiment'].map({'LABEL_1': 1, 'LABEL_0': 0})\n",
    "\n",
    "print(classification_report(my_finetunedf_epo4['recommended'],my_finetunedf_epo4['my_finetune_roberta_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3987f-4bff-49fa-a0fb-8e4609a99472",
   "metadata": {},
   "source": [
    "### Store as xlsx for manual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de44b403-ed79-4f10-829a-94b032d4935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_epo4 = my_finetunedf_epo4[my_finetunedf_epo4['recommended'] != my_finetunedf_epo4['my_finetune_roberta_sentiment']]\n",
    "filtered_df_epo4.to_excel('False_classifications_epo4.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156c280-30d1-4e53-96ee-44b17dd8e487",
   "metadata": {},
   "source": [
    "## Own Fine Tune EPO5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "003639c0-0bf7-4eae-a4d5-f94a82cbbac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.74      1031\n",
      "           1       0.96      0.99      0.97      8588\n",
      "\n",
      "    accuracy                           0.95      9619\n",
      "   macro avg       0.91      0.81      0.85      9619\n",
      "weighted avg       0.95      0.95      0.95      9619\n",
      "\n",
      "CPU times: total: 1min 48s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_path_epo5 = './Fine_tuned_epo5'  # Update model path\n",
    "model_epo5 = RobertaForSequenceClassification.from_pretrained(model_path_epo5)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU (device 0) if available, else use CPU (-1)\n",
    "my_finetune_sentiment_pipeline_epo5 = TextClassificationPipeline(model=model_epo5, tokenizer=tokenizer, framework='pt', device=device, truncation=True)\n",
    "\n",
    "my_finetunedf_epo5 = valid_df.copy()\n",
    "results_epo5 = my_evaluate_sentiment(my_finetunedf_epo5['processed_review'].tolist(),pipeline=my_finetune_sentiment_pipeline_epo5)\n",
    "my_finetunedf_epo5['my_finetune_roberta_sentiment'], my_finetunedf_epo5['my_finetune_roberta_score'] = results_epo5[0], results_epo5[1]\n",
    "my_finetunedf_epo5['my_finetune_roberta_sentiment'] = my_finetunedf_epo5['my_finetune_roberta_sentiment'].map({'LABEL_1': 1, 'LABEL_0': 0})\n",
    "print(classification_report(my_finetunedf_epo5['recommended'],my_finetunedf_epo5['my_finetune_roberta_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24873ea-5694-40d8-8e26-09379bc9aa9c",
   "metadata": {},
   "source": [
    "### Store as xlsx for manual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ff901c-f455-49d3-85fc-070ff0680eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_df_ep05 = my_finetunedf_epo5[my_finetunedf_epo5['recommended'] != my_finetunedf_epo5['my_finetune_roberta_sentiment']]\n",
    "filtered_df_ep05.to_excel('False_classifications_epo5.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13dc104-8af5-48cf-ac80-6ac8c0cdcc3f",
   "metadata": {},
   "source": [
    "## Own Fine Tune EPO10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29250442-644b-41ba-b816-68da1126092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.77      1031\n",
      "           1       0.97      0.98      0.97      8588\n",
      "\n",
      "    accuracy                           0.95      9619\n",
      "   macro avg       0.89      0.86      0.87      9619\n",
      "weighted avg       0.95      0.95      0.95      9619\n",
      "\n",
      "CPU times: total: 1min 46s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_path_epo10 = './Fine_tuned_epo10'  # Update model path\n",
    "model_epo10 = RobertaForSequenceClassification.from_pretrained(model_path_epo10)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU (device 0) if available, else use CPU (-1)\n",
    "my_finetune_sentiment_pipeline_epo10 = TextClassificationPipeline(model=model_epo10, tokenizer=tokenizer, framework='pt', device=device, truncation=True)\n",
    "\n",
    "my_finetunedf_epo10 = valid_df.copy()\n",
    "results = my_evaluate_sentiment(my_finetunedf_epo10['processed_review'].tolist(),pipeline=my_finetune_sentiment_pipeline_epo10)\n",
    "my_finetunedf_epo10['my_finetune_roberta_sentiment'], my_finetunedf_epo10['my_finetune_roberta_score'] = results[0], results[1]\n",
    "my_finetunedf_epo10['my_finetune_roberta_sentiment'] = my_finetunedf_epo10['my_finetune_roberta_sentiment'].map({'LABEL_1': 1, 'LABEL_0': 0})\n",
    "print(classification_report(my_finetunedf_epo10['recommended'],my_finetunedf_epo10['my_finetune_roberta_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d025fadf-5049-45aa-8d23-d28704a75299",
   "metadata": {},
   "source": [
    "## Analysis of misclassification reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35d076a8-8e00-427e-bddd-5397a5e58256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of the 'sarcasm' for baseline model is: 33\n",
      "The number of the 'sarcasm' for Fine-Tuned Model with 4 epochs is: 46\n",
      "The number of the 'sarcasm' for Fine-Tuned Model with 5 epochs is 34\n",
      "The percentage of the 'sarcasm' for baseline model is: 3.20%\n",
      "The percentage of the 'sarcasm' for Fine-Tuned Model with 4 epochs is: 9.89%\n",
      "The percentage of the 'sarcasm' for Fine-Tuned Model with 5 epochs is 7.19%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "Base_analysis = pd.read_excel('base_roberta_mismatched_data.xlsx')\n",
    "EPO4_analysis = pd.read_excel('False_classifications_epo4.xlsx')\n",
    "EPO5_analysis = pd.read_excel('False_classifications_epo5.xlsx')\n",
    "\n",
    "num_sarcasm_base = (Base_analysis['sarcasm'].sum())\n",
    "num_sarcasm_epo4 = (EPO4_analysis['sarcasm'].sum())\n",
    "num_sarcasm_epo5 = (EPO5_analysis['sarcasm'].sum())\n",
    "print(f\"The number of the 'sarcasm' for baseline model is: {num_sarcasm_base:}\")\n",
    "print(f\"The number of the 'sarcasm' for Fine-Tuned Model with 4 epochs is: {num_sarcasm_epo4:}\")\n",
    "print(f\"The number of the 'sarcasm' for Fine-Tuned Model with 5 epochs is {num_sarcasm_epo5:}\")\n",
    "                    \n",
    "\n",
    "percentage_sarcasm_base = (Base_analysis['sarcasm'].sum() / len(Base_analysis)) * 100\n",
    "percentage_sarcasm_epo4 = (EPO4_analysis['sarcasm'].sum() / len(EPO4_analysis)) * 100\n",
    "percentage_sarcasm_epo5 = (EPO5_analysis['sarcasm'].sum() / len(EPO5_analysis)) * 100\n",
    "\n",
    "print(f\"The percentage of the 'sarcasm' for baseline model is: {percentage_sarcasm_base:.2f}%\")\n",
    "print(f\"The percentage of the 'sarcasm' for Fine-Tuned Model with 4 epochs is: {percentage_sarcasm_epo4:.2f}%\")\n",
    "print(f\"The percentage of the 'sarcasm' for Fine-Tuned Model with 5 epochs is {percentage_sarcasm_epo5:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
